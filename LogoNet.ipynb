{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logo detection models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LogoNet: A Robust Layer-Aggregated Dual-Attention Anchorfree Logo Detection Framework with an Adversarial Domain Adaptation Approach"
      ],
      "metadata": {
        "id": "itpJh6hzGreP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import dependencies "
      ],
      "metadata": {
        "id": "1Y6_E6U-O0r0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X-HVeGSGpb_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')\n",
        "shutil.unpack_archive('drive/MyDrive/FlickrLogos-32_dataset_v2.zip', '.')"
      ],
      "metadata": {
        "id": "8amyRveUQeL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87876725-6278-40d3-c36f-e923e8714619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare the data"
      ],
      "metadata": {
        "id": "1VLybQoVqkY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.33)\n",
        "\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "        'FlickrLogos-v2/classes/jpg',\n",
        "        target_size=(256, 256),\n",
        "        subset='training')\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "        'FlickrLogos-v2/classes/jpg',\n",
        "        target_size=(256, 256),\n",
        "        subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpQbDANYZ7B1",
        "outputId": "d2cb2013-87f4-490f-92cc-46336255e4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5524 images belonging to 33 classes.\n",
            "Found 2716 images belonging to 33 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build the model"
      ],
      "metadata": {
        "id": "dYwCrKEkqhBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = keras.Input(shape=(256,256,3))\n",
        "\n",
        "# conv0 = layers.Conv2D(128, 7, strides=2, activation='relu', padding='same', name='conv0')(inputs)\n",
        "# conv1 = layers.Conv2D(256, 3, strides=2, activation='relu', padding='same', name='conv1')(conv0)\n",
        "# conv2 = layers.Conv2D(384, 3, strides=2, activation='relu', padding='same', name='conv2')(conv1)\n",
        "# conv3 = layers.Conv2D(384, 3, strides=2, activation='relu', padding='same', name='conv3')(conv2)\n",
        "# conv4 = layers.Conv2D(384, 3, strides=2, activation='relu', padding='same', name='conv4')(conv3)\n",
        "# conv5 = layers.Conv2D(512, 3, strides=2, activation='relu', padding='same', name='conv5')(conv4)\n",
        "# conv6 = layers.Conv2D(512, 3, strides=1, activation='relu', padding='same', name='conv6')(layers.UpSampling2D(2)(conv5))\n",
        "\n",
        "# conv7 = layers.Conv2D(384, 3, strides=1, activation='relu', padding='same', name='conv7')(conv6)\n",
        "# add = layers.add([conv4, conv7])\n",
        "# conv7 = layers.UpSampling2D(2)(add)\n",
        "\n",
        "# conv8 = layers.Conv2D(384, 3, strides=1, activation='relu', padding='same', name='conv8')(conv7)\n",
        "# add = layers.add([conv3, conv8])\n",
        "# conv8 = layers.UpSampling2D(2)(add)\n",
        "\n",
        "# conv9 = layers.Conv2D(384, 3, strides=1, activation='relu', padding='same', name='conv9')(conv8)\n",
        "# add = layers.add([conv2, conv9])\n",
        "# conv9 = layers.UpSampling2D(2)(add)\n",
        "\n",
        "# conv10 = layers.Conv2D(256, 3, strides=1, activation='relu', padding='same', name='conv10')(conv9)\n",
        "# add = layers.add([conv1, conv10])\n",
        "# conv10 = layers.UpSampling2D(2)(add)\n",
        "\n",
        "# outputs = layers.Flatten()(conv10)\n",
        "# outputs = layers.Dense(33, activation='softmax')(outputs)"
      ],
      "metadata": {
        "id": "ve5xrvWePBP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hg_conv(filters, kernel_size, strides, name):\n",
        "    return layers.Conv2D(filters, kernel_size, strides,\n",
        "                         activation='relu', padding='same', name=name)\n",
        "\n",
        "def resblock(x1, xs, filters, name):\n",
        "    \"\"\"Residual block\"\"\"\n",
        "\n",
        "    layers.BatchNormalization()(x1)\n",
        "    x1 = hg_conv(filters, 3, 1, f'{name}_x1')(x1)\n",
        "    xs = hg_conv(filters, 1, 1, f'{name}_xs')(xs)\n",
        "    x2 = hg_conv(filters, 3, 1, f'{name}_x2')(xs)\n",
        "    x = layers.Add()([x1, x2, xs])\n",
        "    out = layers.ReLU()(x)\n",
        "    out = layers.BatchNormalization()(x)\n",
        "    return layers.UpSampling2D(2)(out)\n",
        "\n",
        "def hourglass(input, hg):\n",
        "    \"\"\"Hourglass module\"\"\"\n",
        "\n",
        "    # the left part of the hourglass\n",
        "    c1 = hg_conv(256, 3, 2, f'hg{hg}_conv1')(input)\n",
        "    c2 = hg_conv(384, 3, 2, f'hg{hg}_conv2')(c1)\n",
        "    c3 = hg_conv(384, 3, 2, f'hg{hg}_conv3')(c2)\n",
        "    c4 = hg_conv(384, 3, 2, f'hg{hg}_conv4')(c3)\n",
        "\n",
        "    # the center of the hourglass\n",
        "    c5 = hg_conv(512, 3, 2, f'hg{hg}_conv5')(c4)\n",
        "\n",
        "    # the right part of the hourglass\n",
        "    c6 = layers.UpSampling2D(2)(hg_conv(512, 3, 1, f'hg{hg}_conv6')(c5)) # don't add the 2 volumes around the middle volume\n",
        "    r = resblock(c6, c4, 384, f'hg{hg}_conv7')\n",
        "    r = resblock(r, c3, 384, f'hg{hg}_conv8')\n",
        "    r = resblock(r, c2, 384, f'hg{hg}_conv9')\n",
        "    r = resblock(r, c1, 256, f'hg{hg}_conv10')\n",
        "    return (c1, r)\n",
        "\n",
        "inputs = keras.Input(shape=(256,256,3))\n",
        "x = hg_conv(128, 7, 2, 'conv0')(inputs)\n",
        "\n",
        "# # The first hourglass\n",
        "# hg1_c1, hg1 = hourglass(x, 1)\n",
        "# x2 = hg_conv(256, 1, 1, 'hg1_conv11')(hg1)\n",
        "# x3 = hg_conv(256, 1, 1, 'hg1_c1_conv11')(hg1_c1)\n",
        "# print(x2.shape, x3.shape)\n",
        "# x = layers.Add()([x2, x3])\n",
        "# x = layers.ReLU()(x)\n",
        "\n",
        "# # The second hourglass\n",
        "# _, hg2 = hourglass(x, 2)\n",
        "# x3 = hg_conv(256, 3, 1, 'hg2_conv11')(hg2)\n",
        "# x = layers.Add()([x2, x3])\n",
        "# x = layers.ReLU()(x)\n",
        "\n",
        "_, x = hourglass(x, 1)\n",
        "x = layers.ReLU()(x)\n",
        "# _, x = hourglass(x, 2)\n",
        "# x = layers.ReLU()(x)\n",
        "\n",
        "outputs = layers.Flatten()(x)\n",
        "outputs = layers.Dense(33, activation='softmax')(outputs)"
      ],
      "metadata": {
        "id": "u5GOc6ae1OM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(inputs=inputs, outputs=outputs, name='LogoNet')\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "uCUbYMcueLke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, \"logonet.png\", show_shapes=True)"
      ],
      "metadata": {
        "id": "6xVHsxJ5ru6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.RMSprop())\n",
        "model.fit(train_generator, validation_data=validation_generator, epochs=5)"
      ],
      "metadata": {
        "id": "Nv9kpGMitAGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbba32d1-c34a-4deb-ed74-119a06fae71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "173/173 [==============================] - 613s 4s/step - loss: 861.1547 - accuracy: 0.4986 - val_loss: 8944.4014 - val_accuracy: 0.7290\n",
            "Epoch 2/5\n",
            "173/173 [==============================] - 558s 3s/step - loss: 203.8283 - accuracy: 0.5203 - val_loss: 1103.4019 - val_accuracy: 0.7290\n",
            "Epoch 3/5\n",
            "173/173 [==============================] - 558s 3s/step - loss: 112.7111 - accuracy: 0.5159 - val_loss: 26.2890 - val_accuracy: 0.7283\n",
            "Epoch 4/5\n",
            "173/173 [==============================] - 554s 3s/step - loss: 42.6546 - accuracy: 0.5469 - val_loss: 38.7439 - val_accuracy: 0.7290\n",
            "Epoch 5/5\n",
            "173/173 [==============================] - 556s 3s/step - loss: 28.8330 - accuracy: 0.5920 - val_loss: 51.9918 - val_accuracy: 0.7257\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe207294c90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im = tf.keras.utils.load_img('/content/FlickrLogos-v2/classes/jpg/google/462663740.jpg')\n",
        "\n",
        "x = tf.keras.utils.img_to_array(im)\n",
        "x = tf.image.resize(x, [256, 256])\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# images = np.vstack([x])\n",
        "model.predict(x)[0]"
      ],
      "metadata": {
        "id": "hf-tg4Z2jqDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b33641-b8f0-4d0d-abf3-4325adba8292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.array(list(train_generator.class_indices.keys()))\n",
        "preds = model.predict(x)[0].astype(int)\n",
        "classes[preds]"
      ],
      "metadata": {
        "id": "lsp5uR-RyqaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9740126-89ae-42a9-8fe7-4e57b926bfa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP',\n",
              "       'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP',\n",
              "       'adidas', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP', 'HP',\n",
              "       'HP', 'HP'], dtype='<U12')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python FlickrLogos-v2/scripts/copy_images_to_flat_dir.py"
      ],
      "metadata": {
        "id": "iSyrc5p9up0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VBEp0nLfqjAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}